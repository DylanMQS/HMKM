{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_features(base_path):\n",
    "    # 读取目录并按数值排序\n",
    "    categories = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    categories.sort(key=int)  # 将目录名转换为整数进行排序\n",
    "    print(categories)\n",
    "    all_features = []\n",
    "    \n",
    "    for category in categories:\n",
    "        category_path = os.path.join(base_path, category)\n",
    "        features_files = [f for f in os.listdir(category_path) if f.endswith('.npy')]\n",
    "        category_features = [np.load(os.path.join(category_path, f)) for f in features_files]\n",
    "        \n",
    "        if category_features:\n",
    "            category_features = np.concatenate(category_features, axis=0)\n",
    "            all_features.append(category_features)\n",
    "    \n",
    "    if all_features:\n",
    "        # 使用 np.stack 添加新的维度来区分不同的类别\n",
    "        all_features = np.stack(all_features, axis=0)\n",
    "    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65']\n"
     ]
    }
   ],
   "source": [
    "coco_attribute_path = \"../exemplar_prototype/coco/ins100_attribute/embeddings/\"\n",
    "all_features = load_and_merge_features(coco_attribute_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 500, 2048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_attribute_save_path = \"../exemplar_prototype/coco/coco_ins100_attribute_perimg.pth\"\n",
    "tensor = torch.from_numpy(all_features)\n",
    "torch.save(tensor, coco_attribute_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单类聚类合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/raid/mqsen/CKDet/exemplar_prototype/coco/ins100_attribute/embeddings/2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/diskb/mqsen_workspace/Detic/files_analysis/coco_attribute_merge.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bia-titan/mnt/diskb/mqsen_workspace/Detic/files_analysis/coco_attribute_merge.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m data_directory \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/raid/mqsen/CKDet/exemplar_prototype/coco/ins100_attribute/embeddings/2\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bia-titan/mnt/diskb/mqsen_workspace/Detic/files_analysis/coco_attribute_merge.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# 加载所有.npy文件\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bia-titan/mnt/diskb/mqsen_workspace/Detic/files_analysis/coco_attribute_merge.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m files \u001b[39m=\u001b[39m [f \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(data_directory) \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bia-titan/mnt/diskb/mqsen_workspace/Detic/files_analysis/coco_attribute_merge.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m data \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(data_directory, f)) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m files]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bia-titan/mnt/diskb/mqsen_workspace/Detic/files_analysis/coco_attribute_merge.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m combined_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(data, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/raid/mqsen/CKDet/exemplar_prototype/coco/ins100_attribute/embeddings/2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 设置数据目录\n",
    "data_directory = '/raid/mqsen/CKDet/exemplar_prototype/coco/ins100_attribute/embeddings/2'\n",
    "\n",
    "# 加载所有.npy文件\n",
    "files = [f for f in os.listdir(data_directory) if f.endswith('.npy')]\n",
    "data = [np.load(os.path.join(data_directory, f)) for f in files]\n",
    "combined_data = np.concatenate(data, axis=0)\n",
    "print(\"combined_data.shape: \", combined_data.shape)\n",
    "# 使用k-means++进行聚类\n",
    "kmeans = KMeans(n_clusters=10, init='k-means++')\n",
    "kmeans.fit(combined_data)\n",
    "\n",
    "# 输出聚类结果\n",
    "print(\"Cluster centers:\", kmeans.cluster_centers_)\n",
    "print(\"Labels:\", kmeans.labels_)\n",
    "print(\"kmeans.cluster_centers_.shape: \", kmeans.cluster_centers_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.mixture import GaussianMixture  # 修改这里\n",
    "\n",
    "# 设置数据目录\n",
    "data_directory = '/raid/mqsen/CKDet/exemplar_prototype/coco/ins100_attribute/embeddings/2'\n",
    "\n",
    "# 加载所有.npy文件\n",
    "files = [f for f in os.listdir(data_directory) if f.endswith('.npy')]\n",
    "data = [np.load(os.path.join(data_directory, f)) for f in files]\n",
    "combined_data = np.concatenate(data, axis=0)\n",
    "print(\"combined_data.shape: \", combined_data.shape)\n",
    "\n",
    "# 使用高斯混合模型（GMM）进行聚类，指定聚类数目\n",
    "gmm = GaussianMixture(n_components=10, init_params='kmeans')  # 替换 KMeans 为 GaussianMixture\n",
    "gmm.fit(combined_data)\n",
    "\n",
    "# 输出聚类结果\n",
    "print(\"Cluster centers:\", gmm.means_)  # GMM 中的簇中心是 gmm.means_\n",
    "print(\"Labels:\", gmm.predict(combined_data))  # 使用 predict 得到数据的簇标签\n",
    "print(\"gmm.means_.shape: \", gmm.means_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, AgglomerativeClustering, Birch\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def load_and_merge_features(base_path, n_clusters, method='kmeans'):\n",
    "    # 读取目录并按数值排序\n",
    "    categories = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    categories.sort(key=int)  # 将目录名转换为整数进行排序\n",
    "    print(categories)\n",
    "    all_features = []\n",
    "    \n",
    "    for category in categories:\n",
    "        category_path = os.path.join(base_path, category)\n",
    "        features_files = [f for f in os.listdir(category_path) if f.endswith('.npy')]\n",
    "        half_length = len(features_files) // 2 # 消融实验用，之后使用要注释掉\n",
    "        features_files = features_files[:half_length] # 消融实验用，之后使用要注释掉\n",
    "        \n",
    "        category_features = [np.load(os.path.join(category_path, f)) for f in features_files]\n",
    "     \n",
    "        if category_features:\n",
    "            category_features = np.concatenate(category_features, axis=0)\n",
    "            \n",
    "            if method == 'kmeans':\n",
    "                kmeans = KMeans(n_clusters=n_clusters, init='k-means++')\n",
    "                kmeans.fit(category_features)\n",
    "                all_features.append(kmeans.cluster_centers_)\n",
    "                \n",
    "            elif method == 'gmm':\n",
    "                gmm = GaussianMixture(n_components=n_clusters, init_params='kmeans')\n",
    "                gmm.fit(category_features)\n",
    "                all_features.append(gmm.means_)\n",
    "                \n",
    "            elif method == 'kmeans++':\n",
    "                kmeans_plus = KMeans(n_clusters=n_clusters, init='k-means++')\n",
    "                kmeans_plus.fit(category_features)\n",
    "                all_features.append(kmeans_plus.cluster_centers_)\n",
    "            elif method == 'agglomerative':\n",
    "                model = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "                model.fit(category_features)\n",
    "                # 注意，AgglomerativeClustering没有 cluster_centers_，这里取每个簇的平均值作为中心\n",
    "                centers = [category_features[model.labels_ == i].mean(axis=0) for i in range(n_clusters)]\n",
    "                all_features.append(np.array(centers))\n",
    "            elif method == 'birch':\n",
    "                model = Birch(n_clusters=n_clusters)\n",
    "                model.fit(category_features)\n",
    "                # Birch 中的簇中心\n",
    "                all_features.append(model.subcluster_centers_)\n",
    "    \n",
    "    if all_features:\n",
    "        # 使用 np.stack 添加新的维度来区分不同的类别\n",
    "        all_features = np.stack(all_features, axis=0)\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# 使用示例\n",
    "coco_attribute_path = \"../exemplar_prototype/coco/ins100_attribute/embeddings/\"\n",
    "n_clusters = 15\n",
    "\n",
    "\n",
    "all_features = load_and_merge_features(coco_attribute_path, n_clusters, method='kmeans++')\n",
    "\n",
    "# 可以选择不同的聚类方法\n",
    "# all_features_kmeans = load_and_merge_features(coco_attribute_path, n_clusters, method='kmeans')\n",
    "# all_features_gmm = load_and_merge_features(coco_attribute_path, n_clusters, method='gmm')\n",
    "# all_features_kmeans_plus = load_and_merge_features(coco_attribute_path, n_clusters, method='kmeans++')\n",
    "# all_features_mini_batch = load_and_merge_features(coco_attribute_path, n_clusters, method='mini_batch_kmeans') # list形式，不难直接用\n",
    "# all_features_agglomerative = load_and_merge_features(coco_attribute_path, n_clusters, method='agglomerative') # all input arrays must have the same shape\n",
    "# all_features_birch = load_and_merge_features(coco_attribute_path, n_clusters, method='birch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_features.shape:  (65, 20, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(\"all_features.shape: \", all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_features_agglomerative.shape:  (65, 15, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(\"all_features_birch.shape: \", all_features_birch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"all_features_kmeans.shape: \", all_features_kmeans.shape)\n",
    "print(\"all_features_kmeans_plus.shape: \", all_features_kmeans.shape)\n",
    "print(\"all_features_gmm.shape: \", all_features_gmm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"kmeans\"\n",
    "coco_attribute_save_path = f\"../exemplar_prototype/coco/coco_ins100_attribute_comparision_{method}.pth\"\n",
    "tensor = torch.from_numpy(all_features_kmeans)\n",
    "torch.save(tensor, coco_attribute_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "method = \"agglomerative\"\n",
    "coco_attribute_save_path = f\"../exemplar_prototype/coco/coco_ins100_attribute_comparision_{method}.pth\"\n",
    "tensor = torch.from_numpy(all_features_agglomerative)\n",
    "torch.save(tensor, coco_attribute_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_attribute_save_path = f\"../exemplar_prototype/coco/coco_ins50_attribute_kmeans{n_clusters}_scale23.pth\"\n",
    "tensor = torch.from_numpy(all_features)\n",
    "torch.save(tensor, coco_attribute_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CKDet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
